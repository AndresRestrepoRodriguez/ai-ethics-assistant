# AI Ethics Assistant - Environment Configuration Template
# Copy this file to .env and fill in your actual values

# =============================================================================
# S3 Configuration
# =============================================================================
# Your S3 bucket containing PDF documents
S3__BUCKET_NAME=your-ai-ethics-bucket

# AWS region where your bucket is located
S3__REGION=us-east-1

# AWS credentials for S3 access
S3__ACCESS_KEY_ID=your-access-key
S3__SECRET_ACCESS_KEY=your-secret-key

# Optional: Folder path within bucket for PDFs (include trailing slash)
S3__PDF_PREFIX=documents/

# =============================================================================
# Qdrant Configuration
# =============================================================================
# Qdrant host (use 'qdrant' for Docker, 'localhost' for local development)
VECTOR_DB__HOST=qdrant

# Qdrant port
VECTOR_DB__PORT=6333

# Collection name for storing document embeddings
VECTOR_DB__COLLECTION_NAME=ai_ethics_docs

# =============================================================================
# Embedding Configuration
# =============================================================================
# Sentence transformer model for generating embeddings
EMBEDDING__MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# Batch size for embedding generation (adjust based on memory)
EMBEDDING__BATCH_SIZE=32

# =============================================================================
# Document Processing Configuration
# =============================================================================
# Text chunk size for optimal RAG performance
CHUNK_SIZE=1000

# Character overlap between chunks to maintain context
CHUNK_OVERLAP=200

# =============================================================================
# LLM Configuration (Optional - for future stages)
# =============================================================================
# Hugging Face API key for Mistral-7B access
# LLM__API_KEY=your-huggingface-token

# Model name for the language model
# LLM__MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2

# =============================================================================
# Development Configuration
# =============================================================================
# Enable development mode features
DEV_MODE=true

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO